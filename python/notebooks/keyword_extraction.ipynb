{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytextrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_content_file = open('stories_pre_processed_content_english.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_content_lines = english_content_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,story_id,story_title,story_english_title,is_child_created_story,stories_status,stories_summary,ancestry,is_recommended_story,reads,language_name,organization_name,page_type,story_derivation_type,story_publishing_type,reading_level_cat,story_content,preprocessed_story_content\n"
     ]
    }
   ],
   "source": [
    "header = english_content_lines[0].strip()\n",
    "print(header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_dict = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_tokens = header.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(header_tokens)):\n",
    "    header_dict[i] = header_tokens[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'story_id', 1: 'story_title', 2: 'story_english_title', 3: 'is_child_created_story', 4: 'stories_status', 5: 'stories_summary', 6: 'ancestry', 7: 'is_recommended_story', 8: 'reads', 9: 'language_name', 10: 'organization_name', 11: 'page_type', 12: 'story_derivation_type', 13: 'story_publishing_type', 14: 'reading_level_cat', 15: 'story_content'}\n"
     ]
    }
   ],
   "source": [
    "print(header_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_record(record, n_tokens=16, delimiter=','):\n",
    "    #merges all the last delimiter separated tokens into 1 token to maintain n_tokens in total.\n",
    "    #this is done because story_content can have commas, which we don't want to split\n",
    "    comma_sep_tokens = record.split(delimiter)\n",
    "    record_tokens = comma_sep_tokens[:n_tokens-1]\n",
    "    record_tokens.append(delimiter.join(comma_sep_tokens[n_tokens-1:]))\n",
    "    return record_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'story_id': '2',\n",
       "  'story_title': 'Smile Please!',\n",
       "  'story_english_title': 'Smile Please!',\n",
       "  'is_child_created_story': 'f',\n",
       "  'stories_status': '1',\n",
       "  'stories_summary': 'Follow the young deer as he races along with friends.',\n",
       "  'ancestry': '1.0',\n",
       "  'is_recommended_story': 't',\n",
       "  'reads': '13981',\n",
       "  'language_name': 'English',\n",
       "  'organization_name': 'Pratham Books',\n",
       "  'page_type': 'StoryPage',\n",
       "  'story_derivation_type': 'Translated',\n",
       "  'story_publishing_type': 'Publisher Story',\n",
       "  'reading_level_cat': '1',\n",
       "  'story_content': '\"A fawn was racing in the forest. He was ahead of the rabbit. He was ahead of the elephant. He leapt and cleared the stream. He ran past the crumbling wall. There was a large boulder on the grassy plain. He stumbled and fell down. He burst into tears. The monkey massaged his leg. Tears flowed from the fawn\\'s eyes. Brother Bear picked him up. The fawn didn\\'t stop crying. His mother came. She said, “Look, we’ll beat up this bad boulder!” The fawn said, “Oh, don’t do that or he will also start crying.” His mother laughed. So did the fawn.\"'},\n",
       " {'story_id': '7',\n",
       "  'story_title': 'Fat King Thin Dog',\n",
       "  'story_english_title': 'Fat King Thin Dog',\n",
       "  'is_child_created_story': 'f',\n",
       "  'stories_status': '1',\n",
       "  'stories_summary': 'Run along with the Fat King after the Thin Dog!',\n",
       "  'ancestry': '',\n",
       "  'is_recommended_story': 't',\n",
       "  'reads': '18996',\n",
       "  'language_name': 'English',\n",
       "  'organization_name': 'Pratham Books',\n",
       "  'page_type': 'StoryPage',\n",
       "  'story_derivation_type': 'Original',\n",
       "  'story_publishing_type': 'Publisher Story',\n",
       "  'reading_level_cat': '1',\n",
       "  'story_content': 'This is a fat king. The fat king has a thin dog. The fat king and his thin dog go for a walk. The dog sees a bird. The dog runs after the bird. The king runs after the dog. They run and run. They run and run for many days. The king catches the dog. Now the fat king is thin.'}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_content_dict_list=[]\n",
    "for l in english_content_lines[1:]:\n",
    "    record = l.strip()\n",
    "    record_tokens = tokenize_record(record, n_tokens=len(header))\n",
    "    record_dict = {}\n",
    "    for i in range(len(record_tokens)):\n",
    "        # converting record like [1,fat king,t] to a more semantic representation like {'s_no':1,'title':'fat king','recommended':'t'}\n",
    "        record_dict[header_dict[i]] = record_tokens[i]\n",
    "    english_content_dict_list.append(record_dict)\n",
    "english_content_dict_list[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa import keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   ['fawn', 'oh', 'look', 'leg', 'flowed', 'large']\n",
      "1   ['king']\n",
      "2   ['gently', 'wind', 'far', 'thank', 'body', 'story', 'sill']\n",
      "3   ['chuskit', 'school', 'abdul', 'children', 'said', 'wooden', 'julley', 'brother', 'grandfather', 'village', 'like', 'trees', 'tree', 'azhang', 'day', 'walk', 'walked', 'gur', 'stream', 'went', 'yes', 'replied', 'away', 'work', 'worked', 'outside', 'making', 'make', 'tea', 'meme', 'hello', 'packed', 'boy', 'disability', 'disabled', 'play', 'teachers', 'yul', 'excited', 'excitedly', 'exciting', 'excitement', 'right', 'rights', 'gonpa', 'class', 'classes', 'chair', 'wheel', 'wheels', 'way', 'ways', 'begged', 'looked', 'looking', 'time', 'times']\n",
      "4   ['story', 'original', 'looking', 'box']\n",
      "5   ['moru', 'children', 'teacher', 'likes', 'liked', 'like', 'looked', 'look', 'looking', 'numbers', 'number', 'school', 'got', 'came', 'broken', 'sat', 'story', 'stories', 'said', 'trees', 'tree', 'little', 'friends', 'catching', 'paper', 'eagle', 'tightly', 'shiny', 'fly', 'flying', 'bigger', 'time', 'wall', 'passed', 'passing', 'felt', 'away', 'unsuspecting', 'people', 'thrown', 'ones', 'tallest', 'smiled', 'smile', 'sorted', 'sort', 'shared', 'bricks', 'brick', 'solving', 'complicated', 'mathematics', 'day', 'days', 'matched', 'hot', 'tears', 'burned', 'bright', 'later', 'raw', 'playground', 'green', 'kids', 'unlike', 'red']\n",
      "6   ['jalebis', 'noisier', 'beating', 'doodom', 'mothers', 'tap', 'yes', 'wonderful', 'hot', 'doodoom']\n",
      "7   ['kicchu', 'choru', 'munia', 'fish', 'fishing', 'said', 'pulled', 'rods', 'little']\n",
      "8   ['kolam', 'susheela', 'draw', 'kolams', 'flour', 'rice', 'colourful', 'know', 'make', 'told']\n",
      "9   ['ji', 'pehelwaan', 'caught', 'hold', 'laughed']\n",
      "10   ['sun', 'come', 'coming', 'india', 'darkness', 'dark', 'night', 'like', 'sister', 'sky', 'torch', 'earth', 'little', 'spinning', 'spin', 'spins', 'tell', 'blanket', 'mother', 'clever', 'pens', 'day', 'home', 'ball', 'turned', 'turn', 'turning', 'turns']\n",
      "11   ['vasant', 'spring', 'holi', 'season', 'chasing', 'chases', 'chase', 'dear', 'frock', 'colour', 'yellow', 'people', 'story']\n",
      "12   ['anu', 'baby', 'aai', 'said', 'aunty', 'oh', 'tell', 'mother', 'small', 'wait', 'clothes', 'called', 'calling', 'asked', 'little', 'frock', 'sister', 'home', 'grow', 'proper', 'curd', 'wake']\n",
      "13   ['anil', 'come', 'let', 'amma', 'crying']\n",
      "14   ['says', 'say', 'snow', 'hot', 'nuts', 'make', 'makes', 'fair', 'winter', 'rajni', 'amma', 'called', 'soft', 'sound', 'green', 'blue', 'caps', 'look', 'roasted', 'roast', 'sankranti', 'watch', 'folk', 'tying', 'contest', 'road']\n",
      "15   ['like', 'called', 'sharat', 'white', 'people', 'says', 'boat', 'moonless', 'hot', 'season', 'seasons', 'celebrate', 'celebrating', 'learning', 'learn', 'indian', 'classical', 'manu', 'nadu']\n",
      "16   ['raining', 'rains', 'rain', 'makes', 'green', 'hot', 'miyan', 'big', 'make', 'called', 'aunty', 'tree', 'trees', 'blew', 'peacocks', 'puffed', 'wet', 'bhaiya', 'rainy', 'grandpa', 'saplings', 'milk', 'ki']\n",
      "17   ['look', 'likes', 'sun', 'looks', 'like', 'half', 'moon', 'feel', 'sad', 'want']\n",
      "18   ['sandy', 'uncle', 'cat', 'oh', 'monkey', 'trees', 'snakes', 'snake', 'rains', 'said', 'tree', 'lives', 'tales', 'tale', 'look', 'looked', 'looking', 'wildlife', 'bark', 'barking', 'people', 'big', 'giant', 'rain', 'came', 'toy', 'let', 'mountains', 'twinkling', 'nasika', 'say', 'saying', 'sadly', 'sad', 'extremely', 'face', 'walk', 'walking', 'frog', 'little', 'prayer', 'protecting', 'protect', 'altitude', 'grasslands', 'woohoo', 'animals', 'lived', 'live', 'told', 'green', 'true', 'ghats', 'ghat', 'come', 'comes']\n",
      "19   ['mummy', 'walking', 'walk', 'say', 'says', 'inside']\n",
      "20   ['tullu', 'bullu', 'came', 'wolf', 'open', 'opened', 'harmless', 'shouted', 'wolves', 'said', 'picked', 'threw', 'climbed', 'broke']\n",
      "21   ['shanti', 'okay', 'miss', 'missing', 'asked', 'flew', 'looked', 'look', 'arun', 'green', 'friends']\n",
      "22   ['publisher', 'story', 'state', 'capital', 'srinagar', 'walking', 'stick', 'workers', 'left', 'old', 'man', 'dentures', 'wore', 'tendulkar', 'sangam']\n",
      "23   ['anu', 'moustache', 'moustaches', 'daddy', 'black', 'looks', 'look', 'onion', 'paper', 'wears', 'wearing', 'glasses', 'white', 'fat', 'tall', 'come', 'comes', 'comb', 'makes', 'make']\n",
      "24   ['story', 'publisher', 'fish', 'cats']\n",
      "25   ['bulbuli', 'totaram', 'jungle', 'jungles', 'hathi', 'said', 'bandaroo', 'asked', 'morning', 'water', 'trees', 'point', 'elaichi', 'little', 'tulsi', 'grew', 'tea', 'senseless', 'hardly', 'hard', 'felt', 'began', 'tree', 'facing', 'whistle', 'smell', 'smelled', 'smells', 'loudly', 'loud', 'place', 'placed', 'plants', 'plant', 'stop', 'stopped', 'breaths', 'breath', 'breathed', 'different', 'village', 'villages', 'eyes', 'cupping', 'cupped', 'cup', 'things', 'thing', 'totatram', 'going', 'away', 'bird', 'birds', 'india', 'forests', 'forest', 'refreshed', 'thanks', 'thank', 'thanked', 'leaves', 'leave', 'war', 'fragrance', 'fragrances', 'split', 'splitting', 'refreshing', 'scents', 'gentle', 'gently', 'passed', 'days', 'day', 'sound', 'humming', 'getting', 'sigh', 'sighed', 'maybe', 'scent', 'bushes', 'bush', 'coconut', 'coconuts', 'red', 'delicious', 'berries', 'feet', 'girl', 'called', 'note', 'notes', 'noise', 'calling', 'face', 'delight', 'delighted', 'went', 'best', 'times', 'time', 'lands', 'landed']\n",
      "26   ['youngest', 'uncle', 'drink', 'cold', 'waiting', 'wait', 'train', 'married']\n",
      "27   ['fish', 'shops', 'shop', 'home', 'father', 'big', 'motorcycles', 'lane', 'cars']\n",
      "28   ['pepe', 'better', 'say', 'says']\n",
      "29   ['shee', 'far', 'away']\n",
      "30   ['anil', 'story', 'came', 'bittu', 'boat', 'original', 'manju', 'smile', 'smiled', 'took', 'crumpled']\n",
      "31   ['ball', 'suraj', 'day', 'singh']\n",
      "32   ['veeru', 'circus', 'laddoo', 'caged', 'lion', 'says', 'say', 'lands', 'inside', 'jumbo', 'wonderful', 'bozo']\n",
      "33   ['gauri', 'scarecrows', 'scarecrow', 'mother', 'red', 'clothes', 'look', 'looked', 'said', 'birds', 'beaks', 'beak', 'ma', 'yellow', 'time', 'old', 'oh', 'away', 'hair', 'hands', 'chomping', 'mud']\n",
      "34   ['things', 'anu', 'new', 'away', 'hair', 'hairs', 'shapes', 'trunks', 'seaside', 'waves', 'trees', 'tree', 'sand', 'daddy']\n",
      "35   ['said', 'poorakha', 'tota', 'zhoola', 'dheema', 'roar', 'darpok', 'bear', 'asked', 'mota', 'squealed', 'hurry', 'lamboo', 'looked', 'look', 'board', 'jumped', 'jump', 'concluded']\n",
      "36   ['trees', 'tree', 'called', 'leaves', 'leaving', 'fruit', 'fruits', 'make', 'making', 'green', 'different', 'flowers', 'flower', 'flowering', 'papaya', 'papayas', 'orange', 'oranges', 'makes', 'delicious', 'brown', 'grows', 'grow', 'growing', 'tamarind', 'insects', 'insect', 'pomegranate', 'pomegranates', 'mango', 'mangoes', 'like', 'likes', 'ripe', 'chikoo', 'chikoos', 'love', 'loved', 'long', 'looked', 'look', 'coconut', 'coconuts', 'guava', 'guavas', 'prince', 'sugar', 'sugared', 'seeds', 'seed', 'red', 'jamun', 'jamuns', 'inside', 'turns', 'turn', 'turned', 'place', 'places', 'colds', 'cold', 'natural', 'sugars', 'gum', 'gums', 'metres', 'metre', 'day', 'days', 'deep', 'skin', 'skins', 'ber', 'bers', 'raw', 'banana', 'bananas', 'jackfruit', 'jackfruits', 'indians', 'indian', 'beings', 'strong', 'tall', 'parts', 'water', 'soil', 'tiny', 'fall', 'falls', 'sweet', 'sweetness', 'eaten', 'colour', 'colouring', 'lord', 'storeyed', 'thirst', 'emperor', 'sharp', 'cone', 'wounds', 'wound', 'food', 'yellow', 'father', 'central', 'smell', 'smelling', 'beautiful', 'beauty', 'good', 'people', 'america', 'graceful', 'proteins', 'protein', 'old', 'black', 'tasty', 'curries', 'hard', 'juicy', 'coughs', 'origin', 'originally', 'lives', 'live', 'living', 'petals', 'dried', 'dry', 'dries', 'drink', 'india', 'drooping', 'droop', 'ice', 'flavour', 'kept', 'purple', 'tangy', 'chewing', 'coastal']\n",
      "37   ['little', 'likes', 'like', 'lightning', 'charged', 'charges', 'particles', 'called', 'air', 'big', 'steel', 'sister', 'negatively', 'negative', 'boooooom', 'woman', 'rain', 'rains', 'leather', 'clever', 'diwali', 'droplets', 'deep', 'tell', 'children', 'thunder', 'elec', 'causing', 'causes', 'equally', 'try', 'quickly']\n",
      "38   ['nice', 'swing', 'bird']\n",
      "39   ['blue', 'little', 'light', 'lights', 'differently', 'different', 'wavelength', 'cloud', 'green', 'clear', 'plastic', 'sister', 'sky', 'wavelengths', 'clever', 'molecules', 'woman', 'orange', 'oh', 'hard', 'hardly', 'water', 'colour', 'colours']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40   ['mother', 'force', 'sister', 'little', 'ball', 'things', 'thing', 'moon', 'apple', 'apples', 'objects', 'heads', 'head', 'big', 'greedy', 'demon', 'silver', 'clever', 'lost', 'cream', 'tell', 'english', 'ago', 'hole', 'called', 'gravity', 'newton', 'universe', 'rubber', 'away']\n",
      "41   ['stars', 'star', 'diamonds', 'new', 'pretty', 'diamond', 'looked', 'like', 'precious', 'called']\n",
      "42   ['feeling', 'pants', 'feel', 'buttons', 'trouble', 'keeps']\n",
      "43   ['maaloo', 'potatoes', 'potato', 'dadi', 'kaaloo', 'looked', 'look', 'looking', 'said', 'fresh']\n",
      "44   ['bunty', 'soaps', 'soap', 'sand', 'bubbly', 'bubbles', 'king']\n",
      "45   ['oh', 'kaka', 'dear', 'munni', 'fields', 'field', 'collage', 'bits', 'flew', 'dry', 'dried', 'word', 'little', 'eggs', 'water', 'wind', 'crow', 'need', 'quickly', 'chirped', 'buffalo', 'grass', 'blacksmith', 'red', 'meaning', 'old', 'greeting', 'flowers', 'chirp']\n",
      "46   ['banana', 'ripe', 'bananas', 'sringeri', 'srinivas', 'shivanna', 'began', 'research', 'carefully', 'away', 'day', 'days', 'big', 'town', 'halwa', 'pooja', 'soon', 'priest', 'help', 'chanting', 'chant']\n",
      "47   ['loco', 'trains', 'new', 'train', 'nearby', 'oooo', 'bull', 'big', 'day', 'driver', 'face', 'oh', 'nadu', 'black', 'exactly', 'felt', 'soon', 'whistle', 'whistling', 'great', 'dear', 'shriek', 'ran', 'babu', 'powerful']\n",
      "48   ['leaves', 'little', 'branches']\n",
      "49   ['paint', 'painted', 'gate', 'veena', 'said', 'vinay']\n",
      "50   ['got', 'cap', 'caps', 'moon', 'pipal', 'mother', 'bought', 'wind', 'smiled', 'smile']\n",
      "51   ['nanhi', 'train', 'got', 'coaches', 'coach']\n",
      "52   ['ringo', 'natkhat', 'gajaraj', 'said', 'legs', 'ran', 'rhin', 'water', 'rhino', 'rhinos', 'deer', 'called', 'swam', 'shy', 'beady', 'necked', 'grass', 'looked', 'look', 'came', 'hemu', 'kalia', 'wild', 'mice', 'hairless', 'rhinoceros']\n",
      "53   ['morning', 'time', 'good']\n",
      "54   ['straight', 'curly']\n",
      "55   ['tinku', 'night', 'friends', 'said', 'ma', 'friend', 'asked', 'lights', 'light', 'moon', 'round', 'eyes', 'turned', 'yes', 'eat']\n",
      "56   ['mannu', 'read', 'teacher', 'different', 'boxes', 'plays', 'play', 'playing', 'bell', 'water', 'green', 'fruits']\n",
      "57   ['ritu', 'grandpa', 'mani', 'post', 'pleece', 'dear', 'aunty', 'pooja', 'bit', 'inside', 'opened', 'make', 'asked', 'uncle', 'little', 'pleeeese', 'wrote', 'reach', 'reached', 'reaches']\n",
      "58   ['sundari', 'ship', 'ships', 'basava', 'man', 'asked', 'ask', 'sailed', 'sail', 'sailing', 'pallava', 'red', 'sails', 'kamboja', 'face', 'faces', 'hair', 'high', 'said', 'look', 'looked', 'looking', 'vegetable', 'vegetables', 'appa', 'bright', 'clothes', 'cloth', 'children', 'slowly', 'small', 'lands', 'carrying', 'exciting', 'flying', 'excitedly', 'eyes', 'bow', 'spices', 'vedas', 'jetty', 'watching', 'watched', 'watch', 'eagerly', 'waiting', 'came', 'oh', 'tamil', 'women', 'especially', 'varman', 'king', 'sold', 'rise', 'narasimha', 'waited', 'colour', 'colours', 'jacket', 'loose', 'astronomy', 'included', 'skins']\n",
      "59   ['bekku', 'different', 'car']\n",
      "60   ['day', 'annual', 'tailor', 'carpenter', 'today', 'oh', 'angry', 'worried']\n",
      "61   ['tasty', 'come']\n",
      "62   ['story', 'stories', 'mango', 'mangoes', 'bring', 'brings', 'appa', 'greeshma', 'playing', 'play', 'times', 'year', 'manoj', 'says', 'trees', 'tree', 'little']\n",
      "63   ['bheema', 'kalu', 'gauri', 'said', 'cheenu', 'asked', 'sneeze', 'moti', 'morning']\n",
      "64   ['kite', 'rabbit', 'chicks', 'little', 'raju', 'bamboo', 'muniya', 'mother', 'fell', 'mangoes', 'flying']\n",
      "65   ['seven', 'years', 'old']\n",
      "66   ['granny', 'toy', 'looked', 'look', 'walk', 'l']\n",
      "67   ['arjun', 'sirishji', 'magic', 'magical', 'liked', 'like', 'woman', 'saree', 'pht', 'worked', 'working', 'work', 'cars', 'boy', 'came', 'longer', 'outside', 'auto', 'autos', 'nagar', 'radiated', 'shah', 'traffic', 'nehru', 'beeped', 'beep', 'beeping', 'aunties', 'mirror', 'life', 'match', 'sisters', 'day', 'looked', 'looking', 'wheels', 'shone', 'canopy', 'touched', 'warm', 'teeth', 'eyes', 'eye', 'began', 'road', 'roads', 'spider', 'bottle', 'bottles', 'gold', 'bollywood', 'broadly', 'drank']\n",
      "68   ['ma', 'manu', 'said', 'rains', 'rain', 'raining', 'asked', 'clouds', 'white', 'cloud', 'today', 'come']\n",
      "69   ['thud', 'chhotu', 'golu', 'leap', 'said', 'coconuts', 'coconut', 'game']\n",
      "70   ['friends', 'friend']\n",
      "71   ['bani', 'mushrooms', 'mushroom', 'children', 'said', 'little', 'shaped', 'yellow', 'come', 'music', 'coming', 'queens', 'ice', 'coloured', 'magic', 'like', 'hats', 'hat', 'juice', 'toy', 'toys', 'white', 'laddoo', 'laddoos', 'mountains', 'mountain', 'saw', 'looked', 'looking', 'flew', 'shouted', 'jigsaw']\n",
      "72   ['chulbul', 'tail', 'tails', 'bombo', 'dr', 'dog', 'fell', 'little', 'shall', 'noise', 'walk', 'walked', 'home', 'time', 'squirrel', 'munching', 'said', 'help', 'walnuts', 'asleep', 'suddenly', 'stood', 'feel']\n",
      "73   ['orange', 'purple', 'flower', 'red', 'black', 'wearing', 'bee', 'hen', 'frog', 'grasshopper']\n",
      "74   ['dragonfly', 'apart', 'dragonflies', 'like', 'shape', 'dead', 'deadly', 'wings', 'hunt', 'hunting', 'insects', 'virtually', 'eyes', 'colourful', 'colours', 'colour', 'small', 'insect', 'damselflies', 'nymphs', 'nymph', 'beautifully', 'plant', 'fly', 'flying', 'flies', 'water', 'actually', 'beautiful', 'bulging', 'near', 'nearly', 'jet', 'jets', 'little', 'horse', 'horses', 'mosquitoes', 'mosquito', 'great', 'strong', 'cellophane', 'engineering', 'neck', 'turn', 'female', 'tree', 'sensitive', 'faintest', 'alarmed', 'shiny', 'waiting', 'wait', 'unfortunate', 'order', 'smaller', 'underwater', 'sperm', 'shapes', 'legs', 'wire', 'time', 'times', 'rice', 'try', 'creeping', 'close', 'abdomen', 'sky', 'skies', 'convenient', 'conveniently', 'thrust', 'start', 'beating', 'started', 'come', 'zooming', 'comes', 'means', 'meaning', 'body', 'bodies', 'days', 'propels', 'propelled', 'japanese', 'farmers', 'tried', 'lives', 'live', 'living', 'good', 'children', 'nasty', 'called', 'spread', 'yellow', 'creep']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'story_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-460331e88cde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_content_dict_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0menglish_content_dict_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords_summa'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_content_dict_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'story_content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menglish_content_dict_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords_summa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'story_content'"
     ]
    }
   ],
   "source": [
    "for i in range(len(english_content_dict_list)):\n",
    "    english_content_dict_list[i]['keywords_summa'] = keywords.keywords(english_content_dict_list[i]['story_content']).split()\n",
    "    print(i,' ',english_content_dict_list[i]['keywords_summa'])\n",
    "    \n",
    "    \n",
    "import json\n",
    "open('summa_results.json','w').write(json.dumps(english_content_dict_list))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experimental - below code, based on pytextrank, is not working and needs to be fixed\n",
    "\n",
    "from pytextrank import normalize_key_phrases, render_ranks, text_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = english_content_dict_list[0]['story_id']\n",
    "text = english_content_dict_list[0]['story_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A fawn was racing in the forest. He was ahead of the rabbit. He was ahead of the elephant. He leapt and cleared the stream. He ran past the crumbling wall. There was a large boulder on the grassy plain. He stumbled and fell down. He burst into tears. The monkey massaged his leg. Tears flowed from the fawn's eyes. Brother Bear picked him up. The fawn didn't stop crying. His mother came. She said, “Look, we’ll beat up this bad boulder!” The fawn said, “Oh, don’t do that or he will also start crying.” His mother laughed. So did the fawn.\"\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_json = {}\n",
    "out_json[\"id\"] = str(id)\n",
    "out_json[\"text\"] = str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '2', 'text': '\"A fawn was racing in the forest. He was ahead of the rabbit. He was ahead of the elephant. He leapt and cleared the stream. He ran past the crumbling wall. There was a large boulder on the grassy plain. He stumbled and fell down. He burst into tears. The monkey massaged his leg. Tears flowed from the fawn\\'s eyes. Brother Bear picked him up. The fawn didn\\'t stop crying. His mother came. She said, “Look, we’ll beat up this bad boulder!” The fawn said, “Oh, don’t do that or he will also start crying.” His mother laughed. So did the fawn.\"'}\n"
     ]
    }
   ],
   "source": [
    "print(out_json)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('outfile.json','w').write(json.dumps(out_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytextrank import json_iter, parse_doc, pretty_print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = 'outfile.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-e1e172d40ece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mgraf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparse_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#    open('stage0','w').write(pretty_print(graf.asdict()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pytextrank/pytextrank.py\u001b[0m in \u001b[0;36mparse_doc\u001b[0;34m(json_iter)\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"graf_text:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraf_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mgrafs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_base_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_graf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraf_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0mbase_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_base_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pytextrank/pytextrank.py\u001b[0m in \u001b[0;36mparse_graf\u001b[0;34m(doc_id, graf_text, base_idx, spacy_nlp)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mspacy_nlp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSPACY_NLP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mSPACY_NLP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mspacy_nlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSPACY_NLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "for graf in parse_doc(json_iter(path0)):\n",
    "    print(graf)\n",
    "#    open('stage0','w').write(pretty_print(graf.asdict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
